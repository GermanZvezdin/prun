Job description
---------------

Job description is represented in the JSON formatted file. So job description
is a set of key-value pairs, where key is a certain job property. Master expects
that job description files are in the "prun/jobs" directory. So this is a good
idea to share this directory in the network for putting job descriptions from
other computers. Following job properties must be set in each job description:

- script
Path to the script file. This script file will be executed on worker computers.
If path is relative, then master will look for the file in the "prun/jobs"
directory. "script" property is closely related to "send_script" property.
If "send_script" value is false, then path must point to a script file on the
remote worker computer, thus path must be absolute.

- send_script
Whether master sends content of a script file or not. It is possible to send
script file content to workers without sharing this script file across network.
If file is large, then there is a problem of sending too much data, devouring
network bandwidth.
Also, if script file size is larger than 512 Kb, then it is necessary to set
"send_script" value to false, because of some worker's internal limitations.

- language
Script language might be one of the following: python, ruby, js, java, shell.

- priority
The smaller the integer value of the "priority" option, the higher the priority
of the job. Job with a higher priority will be scheduled before another job with
a lower priority.

- job_timeout
Job timeout in seconds. If scheduled by the master job is not completed in a
period of job_timeout seconds, then master sends "stop job" command to all job
executing workers.

- queue_timeout
All incoming master jobs are queued. If master doesn't schedule the job in a
period of queue_timeout seconds, then this job will be removed from the job
queue.

- task_timeout
Task timeout in seconds. This timeout means task execution timeout. If the
running process is not completed in a period of task_timeout seconds, then
supervising worker process will terminate it immediately.

NOTE: Negative timeout value means infinite timeout.

- max_failed_nodes
Maximum number of failed nodes whereupon job will be stopped on all workers.

- num_execution
Integer number of planned job executions. If the value is negative, then the
number of planned job executions is dependent on max_cluster_cpu property as
follows: if the value of max_cluster_cpu if negative, then the number of
planned job executions equals to the total number of cluster CPUs, otherwise
it equals to MIN( max_cluster_cpu, total_number_cpu ).

- max_cluster_cpu
Maximum number of simultaneously running instances of the job in the cluster.
Negative value means no limits.

- max_cpu
Maximum number of simultaneously running instances of the job in the single
worker machine. Negative value means no limits.

- exclusive
Exclusive job couldn't be executed simultaneously with any other job.

- no_reschedule
If the value is false, then master reassigns job from failed worker to any other
free worker, otherwise job won't be reassigned.

- hosts (optional)
List of hosts that are allowed to execute job. Empty list means no limits.

- groups (optional)
List of groups of hosts, that are allowed to execute job. Empty list means no
limits.

Job requirements
-----------------

In general, to create a job, do one of the following: write script that will
perform the actual job itself or will start another program that will perform
the job. Supported scripting languages are presented in the job description
section. Master expects that script files are in the "prun/jobs" directory.

Master will execute a job multiple times across cluster machines. Each
particularly running job is called a "task". So the "job" is a set of "tasks".
Number of tasks depends on job properties "num_execution", "max_cluster_cpu"
and the total number of cluster CPUs (for more detailed information see job
description section).
When Worker starts your script (aka "task"), it passes three input parameters:
"taskId", "numTasks" and "jobId". The meaning of first two parameters are close
to MPI's MPI_Comm_rank and MPI_Comm_size respectively. The value of "numTasks"
parameter is the number of planned job executions. The value of "taskId"
parameter is an integer identifier of a currently running task, that lies in
the half-closed interval [0, "numTasks"). The value of "jobId" parameter is an
integer identifier of currently running job. Note that "jobId" is a unique
identifier only in a context of running Master session. So, after restart of a
Master process, the value of "jobId" parameter for newly running tasks may be
equal to such one "jobId" value of previously running jobs.

Each running job returns its completion status to a supervising Worker process.
If job is written in one of supported script languages (e.g Python or Ruby),
then it should throw an exception to return its negative completion status,
while returning positive completion status doesn't require any additional action.
Note that shell scripts or running binary executables must return its exit code
as a completion status, while other script languages shouldn't call "exit"
command, because of its execution within a context of supervising script.
As usually, zero exit code means normal completion status, while non-zero value
would be interpreted by a Master as job failure, so Master possibly reassigns
that job to any other node as it mentioned above in the job description section.

Job dependency graph. Metajobs
------------------------------


Workers and worker groups management
------------------------------------

Workers are identified by a hostname or host ip. Set of workers is called worker
group. Workers always belong to some worker group. Master reads "hosts" file
during its initialization. This "hosts" file is in the "prun" directory, it
contains list of worker groups. Master expects that worker group files are also
in the "prun" directory. So, if you are deployed workers, you should create
text file, which contains hostnames or IP's of worker machines (line by line).
This text file must be named as the name of worker group. Then you just append
this group name to the end of "hosts" file.
Also it is possible to manually manage workers, using admin tool (see
administration tool section). It is possible to add or delete workers, worker
groups on the fly.
So Master must know about Workers, but Workers should not know anything about
Master, therefore connecting Master with Workers consists only of steps
described above.
Master takes into account computer specifications. Computer with lots of RAM and
free CPU's is more likely to get a job.

Master and Worker configuration
-------------------------------

Administration tool
-------------------